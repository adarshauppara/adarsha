{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1RWJ9440bApq4atu5rR-G96iG7NCxeJON",
      "authorship_tag": "ABX9TyOmsbRO71UdizvS1rvmJuiJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adarshauppara/adarsha/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XB3Q2PP700-"
      },
      "source": [
        "Automate Identification And Recognition Of Handwritten Text from An Image.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeOQOnqn75KR"
      },
      "source": [
        "Name Of The Student : Jaison Jaideep Lobo\r\n",
        "\r\n",
        "Internship Project Title : Automate Identification and Recognition of Handwritten Text from an Image\r\n",
        "\r\n",
        "Name of the Organization : TCS iON\r\n",
        "\r\n",
        "Name of the Industry Mentor : A Chatterjee\r\n",
        "\r\n",
        "Name of the Institute : Alvaâ€™s institute of engineering and technology, Mijar, Moodbidiri\r\n",
        "\r\n",
        "Name of the Academic Mentor : Hemanth Kumar N P\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyuZbR0B8eVs"
      },
      "source": [
        "**Introduction:**\r\n",
        "\r\n",
        "An optical character recognition problem is basically a type of image-based sequence recognition problem. And for sequence recognition problem, most suited neural networks are recurrent neural networks(RNN) while for an image-based problem most suited are convolution neural networks(CNN). To cop up with the OCR problems we need to combine both of these CNN and RNN and use SoftMax."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncw-ZyX98l3V"
      },
      "source": [
        "Steps being followed are as follows:\r\n",
        "The complete implementation of the project can be divided into the following major steps:\r\n",
        "\r\n",
        "1. Collecting the Dataset.\r\n",
        "\r\n",
        "2. Uploading the dataset into the Google Drive.\r\n",
        "\r\n",
        "3. Preprocessing the data.\r\n",
        "\r\n",
        "4. Dividing the dataset into train, test and validation sets.\r\n",
        "\r\n",
        "5. Creating the defining the model/network architecture.\r\n",
        "\r\n",
        "6. Training the model.\r\n",
        "\r\n",
        "7. Saving the model.\r\n",
        "\r\n",
        "8. Testing the model.\r\n",
        "\r\n",
        "9. Prediction.\r\n",
        "\r\n",
        "10. Plotting the loss and accuracy plots."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUtjvnCZ8rzM"
      },
      "source": [
        "Step 1: Collecting the Dataset\r\n",
        "we used IAM handwritten datset. This is good dataset with several preprocessing already done.\r\n",
        "\r\n",
        "To download the dataset either you can directly download from this link or use the following commands to download the data and unzip.\r\n",
        "\r\n",
        "My data subset which I am using for training and testing hgaving around 4900 images can be found on this link."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtHsK46Aky0x"
      },
      "source": [
        " \n",
        "from __future__ import division\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from random import *\n",
        "from PIL import Image\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import matplotlib.image as mpimg\n",
        "# %matplotlib inline\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU, Activation, BatchNormalization\n",
        "from keras.layers.convolutional import Convolution2D, Cropping2D, ZeroPadding2D, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msW21wMQ8-mE"
      },
      "source": [
        "Step 2: Uploading the Dataset on GDrive and acessing it.\r\n",
        "After uploading the dataset accessing the content stored in GDrive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIAUjTcJd5bS",
        "outputId": "36959f32-203c-44e1-d7cd-9f0160ee975f"
      },
      "source": [
        "from google.colab import drive\r\n",
        " \r\n",
        "drive.mount('/content/gdrive')\r\n",
        "d = {}\r\n",
        "from subprocess import check_output\r\n",
        "with open('/content/gdrive/MyDrive/tcs/formss.txt') as f:\r\n",
        "  for line in f:\r\n",
        "    key = line.split(' ')[0]\r\n",
        "    writer = line.split(' ')[1]\r\n",
        "    d[key] = writer\r\n",
        "print(len(d.keys()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "1539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXxFy7Y_-iDA"
      },
      "source": [
        "**Step 3: Preprocessing the Data.**\r\n",
        "\r\n",
        "After fetching the dataset we will preprocess the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjK52szy-qy3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8519fef-16dc-4bb0-a72b-81921e5d21b7"
      },
      "source": [
        "tmp=[]\r\n",
        "target_list = []\r\n",
        "path_to_files = os.path.join('gdrive/My Drive/tcs/data_subset','*')\r\n",
        "for filename in sorted(glob.glob(path_to_files)):    \r\n",
        "    tmp.append(filename)\r\n",
        "    image_name = filename.split('/')[-1]\r\n",
        "    file, ext = os.path.splitext(image_name)\r\n",
        "    parts = file.split('-')\r\n",
        "    print(parts)\r\n",
        "    form = parts[0] + '-' + parts[1]\r\n",
        "    \r\n",
        "    for key in d:\r\n",
        "        if key == form:\r\n",
        "            target_list.append(str(d[form]))\r\n",
        " \r\n",
        "img_files = np.asarray(tmp)\r\n",
        "img_targets = np.asarray(target_list)\r\n",
        "print(img_files)\r\n",
        "print(img_targets)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czvRXAE_S7jK"
      },
      "source": [
        "## **Visualising the Data.**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPbsWRc4TOsN"
      },
      "source": [
        "import matplotlib.image as mpimg\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "for filename in img_files[6:15]:\r\n",
        "    img=mpimg.imread(filename)\r\n",
        "    plt.figure(figsize=(10,10))\r\n",
        "    plt.imshow(img, cmap ='gray')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYDjFuOEyjpx",
        "outputId": "692a0387-e0d5-49dd-c141-cf35c2378fbc"
      },
      "source": [
        "encoder = LabelEncoder()\r\n",
        "encoder.fit(img_targets)\r\n",
        "encoded_Y = encoder.transform(img_targets)\r\n",
        " \r\n",
        "print(img_files[6:15], img_targets[6:15], encoded_Y[6:15])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[] [] []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHDMfR8_yuHN"
      },
      "source": [
        "**Step 4: Dividing the dataset into train, test and validation sets.**\r\n",
        "\r\n",
        "After sptlitting we have 3240 train images, 835 test and validation images each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqGYA9rfy1BC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "train_files, rem_files, train_targets, rem_targets = train_test_split(\r\n",
        "        img_files, encoded_Y, train_size=0.66, random_state=52, shuffle= True)\r\n",
        " \r\n",
        "validation_files, test_files, validation_targets, test_targets = train_test_split(\r\n",
        "        rem_files, rem_targets, train_size=0.5, random_state=22, shuffle=True)\r\n",
        " \r\n",
        "print(train_files.shape, validation_files.shape, test_files.shape)\r\n",
        "print(train_targets.shape, validation_targets.shape, test_targets.shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}